{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep learning architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will construct a number of different network architectures and compare their performance. For all of the following we perform a coarse hyperparameter selection (by hand) using the test set: you should **report the hyperparameters you found**, and **plot the training and test classification accuracy as a function of iteration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable # not found in torch 0.4\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#transform = transforms.Compose([transforms.ToTensor(), \n",
    "#                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_acc(train_acc, test_acc, losses):\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches([12, 6])\n",
    "    \n",
    "    plt.plot(train_acc, 'y', alpha = 0.5, label = 'Training Accuracy')\n",
    "    plt.plot(test_acc, 'r', alpha = 0.5, label = 'Testing Accuracy')\n",
    "    plt.plot(losses/np.max(losses), 'g', alpha = 0.5, label = 'Loss')\n",
    "    plt.ylabel('Accuracy'); plt.xlabel('Interations')\n",
    "    plt.ylim(0, plt.ylim()[1]); plt.ylim(0, 1)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dog             truck             horse             plane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd651bd9160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    norm_img = (npimg - np.min(npimg))/(np.max(npimg) - np.min(npimg)) # min-max normalization\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches([12, 6])\n",
    "    plt.imshow(np.transpose(norm_img, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "data_iterator = iter(trainloader)\n",
    "images, labels = data_iterator.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images)) # show images\n",
    "print(' '.join('%17s' % classes[labels[j]] for j in range(4))) # print labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0,0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase batch_size\n",
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a) - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fully connected output, $0$ hidden layers (logistic regression):** \n",
    "\n",
    "We begin with the simplest network possible that has no hidden layers and simply linearly maps the input layer to the output layer. That is, conceptually it could be written as\n",
    "\n",
    "$$ x^{out} = W\\cdot \\text{vec}(x^{in}) + b $$\n",
    "\n",
    "where $x^{out} \\in \\mathbb{R}^{10}$, $x^{in} \\in \\mathbb{R}^{32 \\times 32 \\times 3}$, $W \\in \\mathbb{R}^{10, 3072}$, $b \\in \\mathbb{R}^{10}$ where $3072 = 32 \\cdot 32 \\cdot 3$. For a tensor $x \\in \\mathbb{R}^{a \\times b \\times c}$, we let vec$(x) \\in \\mathbb{R}^{abc}$ be the reshaped from a tensor into a vector (in an arbitrary but consistent pattern)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model for part (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()    \n",
    "        self.linear = nn.Linear(32*32*3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32*32*3)\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_net = LinearRegression().cuda()\n",
    "lr_net = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(lr_net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designate your performance metric (accuracy in our case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, linear=False):\n",
    "    correct, total = 0, 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        #if(linear):\n",
    "        #    images = images.view(-1, 32*32*3) # using linear layer, not convolutional\n",
    "        #outputs = model(Variable(images.cuda()))\n",
    "        outputs = model(Variable(images))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        #correct += (predicted == labels.cuda()).sum()\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    return correct/total\n",
    "\n",
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train + Evaluate concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "addmm(): argument 'mat1' (position 1) must be Variable, not torch.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d5bc52c3616a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-35271dd0fcfc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: addmm(): argument 'mat1' (position 1) must be Variable, not torch.FloatTensor"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = lr_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_accuracy_a, test_accuracy_a = [], []\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs       \n",
    "        inputs, labels = data\n",
    "        #inputs = inputs.view(-1, 32*32*3)\n",
    "        # wrap them in Variable\n",
    "        #inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        inputs, labels = Variable(inputs, Variable(labels))\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize (this is all there is)\n",
    "        outputs = lr_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        minibatchs = 4000\n",
    "        if i % minibatchs == minibatchs - 1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / minibatchs))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            # performance on training data\n",
    "            train_acc = evaluate(trainloader, lr_net)           \n",
    "            train_accuracy_a.append(train_acc)\n",
    "            print('Accuracy of the network on the 50000 training images: %d %%' % (100 * train_acc))\n",
    "            \n",
    "            # performance on validation/test set\n",
    "            test_acc = evaluate(testloader, lr_net)\n",
    "            test_accuracy_a.append(test_acc)\n",
    "            print('Accuracy of the network on the 10000 test images: %d %%' % (100 * test_acc))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The training stage can be abstracted.** Notice that we have only hardcoded the dataset and the print statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, trainloader, testloader, criterion, optimizer, epochs=1, linear=False, weight_decay=False):\n",
    "    train_accuracy, test_accuracy, loss_list = [], [], []\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs       \n",
    "            inputs, labels = data\n",
    "            #if linear:\n",
    "            #    inputs = inputs.view(-1, 32*32*3)\n",
    "                \n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "      \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize (this is all there is)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "\n",
    "        train_acc = evaluate(trainloader, model, linear) \n",
    "        train_accuracy.append(train_acc)\n",
    "\n",
    "        test_acc = evaluate(testloader, model, linear)\n",
    "        test_accuracy.append(test_acc)\n",
    "        loss_list.append(loss.data[0])\n",
    "        \n",
    "        # Decay learning rate\n",
    "        if weight_decay and (epoch+1) % 20 == 0:\n",
    "            curr_lr /= 3\n",
    "            update_lr(optimizer, curr_lr)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print('[Epoch %2d ||  Train acc: %d %% | Test acc: %d %% | loss: %.3f ]' \n",
    "                              % (epoch, train_acc*100, test_acc*100, running_loss/(len(trainloader))))\n",
    "\n",
    "    print('Finished Training')\n",
    "    return model, train_accuracy, test_accuracy, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust batch_size\n",
    "batch_size=64\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_net = LinearRegression().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(lr_net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_net, train_acc, test_acc, losses = train(lr_net, trainloader, testloader,\n",
    "                                           criterion, optimizer, epochs=5, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(train_acc, test_acc, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Part (b)\n",
    "\n",
    "Fully connected output, 1 fully connected hidden layer: we will have one hidden layber denoted as $x^{hidden} \\in \\mathbb{R}^M$ where $M$ will be a hyperparameter you choose ($M$ could be in the hundreds). the nonlinearity appled to the hidden layer will be the relu (relu$(x) = \\max\\{0, x\\}$, elementwise). Conceptionally, one cold write this network as:\n",
    "\n",
    "$$ x^{out} = W_2\\text{relu}(W_1\\text{vec}(x^{in}) + b_1) + b_2$$\n",
    "\n",
    "where $W_1 \\in \\mathbb{R}^{M \\times 3072}, b_1 \\in \\mathbb{R}^M, W_2 \\in \\mathbb{R}^{10 \\times M}, b_2 \\in \\mathbb{R}^10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "M = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class OneHidden(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneHidden, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, M)\n",
    "        self.fc2 = nn.Linear(M, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_one_hidden = OneHidden().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "batch_size=32\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_one_hidden.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(net.parameters(), betas = (0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model, train_acc, test_acc, losses = train(model_one_hidden, trainloader, testloader,\n",
    "                                           criterion, optimizer, epochs=25, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_acc(train_acc, test_acc, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c)\n",
    "\n",
    "\n",
    "Fully connected output, 1 convolutional layer with max-pool: for a convolutional layer $W_1$ with individual filters of size $p \\times p \\times 3$ and output size $M$ (resonable choices are $M = 100, p = 5$) we have that Conv2d$(x^{input}, W_1) \\in \\mathbb{R}^{(33 - p)\\times (33 - p) \\times M}$. Each convolution will have its own offset applied to each of the output pixels of the convolution; we denote this as Conv2d$(x^{input}, W) + b_1$ where $b_1$ is parameterized in $\\mathbb{R}^M$. We will then apply a relu (relu doesn't change the tensor space) and pool. If we use a max-pool of size $N$ (a resonable choise is $N = 14$ to pool to $2 \\times 2$ with $p = 5$) we have that \n",
    "\n",
    "$$ \\text{MaxPool(relu(Conv2d}(x^{input}, W_1) + b_1)) \\in \\mathbb{R}^{\\lfloor \\frac{33-p}{N} \\rfloor \\times \\lfloor \\frac{33- p}{N} \\rfloor \\times M}.$$\n",
    "\n",
    "We will then apply a fully connected layer to the output to get the final network given as\n",
    "\n",
    "$$ x^{out} = W_2\\text{vec}(\\text{MaxPool}(\\text{relu}(\\text{Conv2d}(x^{in}, W_1) + b_1))) + b_2$$\n",
    "\n",
    "where $W_2 \\in \\mathbb{R}^{10 \\times M(\\lfloor \\frac{33-p}{N} \\rfloor)^2}, b_2 \\in \\mathbb{R}^{10}$. The parameters $M, p, N$ (in addition to the stap size and the momentum are all hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 5 ## size of the kernel / filter (that we are sliding along)\n",
    "M = 100 ## \n",
    "N = 14\n",
    "input_size = 32\n",
    "output_size = 10\n",
    "channel_nb = 3\n",
    "\n",
    "# M = 6; N = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.floor_divide(input_size + 1 - p, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_divide = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneConv, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channel_nb, M, p) ## 6x28x28 28 = 33-5\n",
    "        self.pool = nn.MaxPool2d(N, N) ## 6 x 14 x 14\n",
    "        self.fc1 = nn.Linear(M * floor_divide * floor_divide, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, M * floor_divide * floor_divide)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one_conv = OneConv().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "batch_size=64\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_one_conv.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(net.parameters(), betas = (0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_acc, test_acc, losses = train(model_one_conv, trainloader, testloader,\n",
    "                                           criterion, optimizer, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(train_acc, test_acc, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (d)\n",
    "\n",
    "(Extra credit: [5 points] ) Returning to the original network you were left with at the end of the tutorial Training a classifier, tune the different hyperparameters (number of convolutional filters, filter sizes, dimensionality of the fully connected layers, stepsize, etc.) and train for many epochs to achieve a test accuracy of at least 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the model we are using ##\n",
    "\n",
    "conv_size1 = 5 ## size of the kernel / filter (that we are sliding along)\n",
    "conv_size2 = 3\n",
    "num_hidden_nodes = 128 ## \n",
    "N = 2\n",
    "input_size = 32\n",
    "output_size = 10\n",
    "channel_nb = 3\n",
    "pool_size = 2\n",
    "#first_layer_size = np.floor(input_size + 1 - conv_size1, pool_size)\n",
    "#second_layer_size = np.floor(first_layer_size + 1 - conv_size2, pool_size)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channel_nb, num_hidden_nodes, conv_size1, padding = 2) # 6 x 28 x 28 (filer = 5)   || 26 x 26 x 6\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 6 x 14 x 14 (filer = 5) 9 || 6 x 13 x 13 || 16\n",
    "        self.conv2 = nn.Conv2d(num_hidden_nodes, 256, 3, padding = 1) # 16 x 10 x 10 || 16 x 9 x 9 \n",
    "        self.conv3 = nn.Conv2d(256, 512, 3, padding = 1) # 16 x 10 x 10 || 16 x 9 x 9 \n",
    "        self.fc1 = nn.Linear(512 * 4 * 4, 2048) ## 5 = 10/2 (another pooling), but I don't know where 16 comes from?\n",
    "        self.fc2 = nn.Linear(2048, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 512 * 4 * 4) ## should be 1024\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(net.parameters(), betas = (0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_acc, test_acc, losses = train(net, trainloader, testloader,\n",
    "                                           criterion, optimizer, epochs=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(train_acc, test_acc, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy on particular classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    inputs, labels = Variable(images.cuda()), Variable(labels.cuda())\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    \n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[int(label.data)] += c[i]\n",
    "        class_total[int(label.data)] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evaluate(testloader, model, linear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[0], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[1], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet(ResidualBlock, [2, 2, 2, 2]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(net.parameters(), betas = (0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet, train_acc, test_acc, losses = train(resnet, trainloader, testloader,\n",
    "                                           criterion, optimizer, epochs=120, weight_decay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(train_acc, test_acc, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
